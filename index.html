<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN"
    "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">

<head>
    <meta http-equiv="content-type" content="text/html; charset=utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Mario Geiger</title>
    <link rel="stylesheet" type="text/css" href="style.css">
    <!--<script type="text/javascript" src="script.js"></script>-->
    <link href="https://fonts.googleapis.com/css?family=Nunito" rel="stylesheet">
</head>

<body>
    <div class="topnav">
        <a href="https://github.com/mariogeiger">Github</a>
        <a href="https://people.epfl.ch/mario.geiger">EPFL</a>
        <a href="https://scholar.google.it/citations?user=Py69D_8AAAAJ">Google Scholar</a>
    </div>

    <div class="content">
        <img src="me.jpg" alt="A photography of me">
        <p>My name is <strong>Mario Geiger</strong>. I'm working on neural networks. I live in Switzerland. I speak French and English. I like to study the dynamics of neural network and develop equivariant architectures. My favorite ice cream flavor is pistachio.</p>
        <h2>CV</h2>
        <ul>
            <li>PhD with Prof. Matthieu Wyart [<a href="https://pcsl.epfl.ch">pcsl</a>] (2017-2021)</li>
            <li>EPFL in physics (2012-2017)</li>
            <li>CFC of laboratory worker in physics (2006-2010)</li>
        </ul>

        <h2>Publications</h2>
        <ul>
            <li>[13] SE(3)-Equivariant Graph Neural Networks for Data-Efficient and Accurate Interatomic Potentials [<a href="https://arxiv.org/abs/2101.03164">arXiv</a>]</li>
            <li>[13] How memory architecture affects performance and learning in simple POMDPs [<a href="https://arxiv.org/abs/2106.08849">arXiv</a>]</li>
            <li>[12] SE(3)-equivariant prediction of molecular wavefunctions and electronic densities [<a href="https://arxiv.org/abs/2106.02347">arXiv</a>]</li>
            <li>[11] Relative stability toward diffeomorphisms in deep nets indicates performance [<a href="https://arxiv.org/abs/2105.02468">arXiv</a>]</li>
            <li>[10] Landscape and training regimes in deep learning [<a href="https://arxiv.org/abs/2012.15110">arXiv</a>] [<a href="https://doi.org/10.1016/j.physrep.2021.04.001">doi</a>]</li>
            <li>[9] Geometric compression of invariant manifolds in neural nets [<a href="https://doi.org/10.1088/1742-5468/abf1f3">doi</a>] [<a href="https://arxiv.org/abs/2007.11471">arXiv</a>][<a href="https://github.com/mariogeiger/feature_lazy/tree/compressing_invariant_manifolds">git</a>]</li>
            <li>[8] Finding symmetry breaking order parameters with Euclidean neural networks [<a href="https://doi.org/10.1103/PhysRevResearch.3.L012002">doi</a>]</li>
            <li>[7] Disentangling feature and lazy training in deep neural networks [<a href="https://doi.org/10.1088/1742-5468/abc4de">doi</a>][<a href="https://arxiv.org/abs/1906.08034">arXiv</a>][<a href="https://github.com/mariogeiger/feature_lazy/tree/article">git</a>]</li>
            <li>[6] Asymptotic learning curves of kernel methods [<a href="https://doi.org/10.1088/1742-5468/abc61d">doi</a>] [<a href="https://arxiv.org/abs/1905.10843">arXiv</a>]</li>
            <li>[5] Scaling description of generalization with number of parameters in deep learning [<a href="https://doi.org/10.1088/1742-5468/ab633c">doi</a>] [<a href="https://arxiv.org/abs/1901.01608">arXiv</a>]</li>
            <li>[4] A jamming transition from under- to over-parametrization affects generalization in deep learning [<a href="https://doi.org/10.1088/1751-8121/ab4c8b">doi</a>] [<a href="https://arxiv.org/abs/1810.09665">arXiv</a>] [<a href="https://github.com/mariogeiger/nn_jamming">git</a>]</li>
            <li>[3] Jamming transition as a paradigm to understand the loss landscape of deep neural networks [<a href="https://doi.org/10.1103/PhysRevE.100.012115">doi</a>] [<a href="https://arxiv.org/abs/1809.09349">arXiv</a>]</li>
            <li>[2] A General Theory of Equivariant CNNs on Homogeneous Spaces [<a href="https://proceedings.neurips.cc/paper/2019/hash/b9cfe8b6042cf759dc4c0cccb27a6737-Abstract.html">NeurIPS 2019</a>] [<a href="https://arxiv.org/abs/1811.02017">arXiv</a>]</li>
            <li>[1] 3D Steerable CNNs [<a href="https://proceedings.neurips.cc/paper/2018/hash/488e4104520c6aab692863cc1dba45af-Abstract.html">NeurIPS 2018</a>] [<a href="https://arxiv.org/abs/1807.02547">arXiv</a>][<a href="https://github.com/mariogeiger/se3cnn">git</a>][<a href="https://youtu.be/ENLJACPHSEA">youtube</a>]</li>
            <li>[0] Spherical CNNs [<a href="https://openreview.net/pdf?id=Hkbd5xZRb">ICLR 2018</a>][<a href="https://github.com/jonas-koehler/s2cnn">git</a>]</li>
        </ul>

        <h2>Selected repositories</h2>
        <ul>
            <li><a href="https://github.com/e3nn/e3nn">github.com/e3nn/e3nn</a> PyTorch library for equivariant neural networks</li>
            <li><a href="https://github.com/mariogeiger/jarzynski">github.com/mariogeiger/jarzynski</a> hard spheres collisions with no time steps</li>
            <li><a href="https://github.com/agepoly/wish">github.com/agepoly/wish</a> website interface for the matching problem</li>
            <li><a href="https://github.com/mariogeiger/grid">github.com/mariogeiger/grid</a> library to save and load numerical experiments</li>
            <li><a href="https://github.com/mariogeiger/negamax">github.com/mariogeiger/negamax</a> small rust implementation of negamax algorithm</li>
            <li><a href="https://github.com/mariogeiger/thinfilm">github.com/mariogeiger/thinfilm</a> implementation of multilayer refraction and transmission</li>
        </ul>

        <!-- <h2>Other stuff</h2>
        <ul>
            <li><a href="qft_cosmo.pdf">physics form</a></li>
        </ul> -->

        <h2>Contact</h2>
        <p>mge at ik dot me</p>
    </div>

    <div class="footer">
        Mario Geiger
    </div>
</body>

</html>
